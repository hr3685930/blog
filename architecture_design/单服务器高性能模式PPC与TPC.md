# 单服务器高性能模式:PPC与TPC

高性能架构设计：单服务器性能发挥到极致,设计服务器集群方案，还和具体实现及编码相关。

单服务器高性能:  并发模型：如何管理连接、处理请求，和操作系统I/O及进程模型相关。

- I/O 模型：阻塞、非阻塞、同步、异步。
- 进程模型：单进程、多进程、多线程。
- 单服务器高性能：PPC 与 TPC。


## PPC
> Process Per Connection，有新连接就新建进程处理，传统的UNIX网络服务器用  

![](%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8FPPC%E4%B8%8ETPC/657D4E1E-08F9-4D70-9250-AC47F5F98F6B.png)
父进程接受连接（图中 accept）。
父进程“fork”子进程（图中 fork）。
子进程处理连接的读写请求（图中子进程 read、业务处理、write）。
子进程关闭连接（图中子进程中的 close）。

注意，图中有一个小细节，父进程“fork”子进程后，直接调用了 close，看起来好像是关闭了连接，其实只是将连接的文件描述符引用计数减一，真正的关闭连接是等子进程也调用 close 后，连接对应的文件描述符引用计数变为 0 后，操作系统才会真正关闭连接，更多细节请参考《UNIX 网络编程：卷一》。

PPC 模式实现简单，比较适合服务器的连接数没那么多的情况，例如数据库服务器。


### 弊端
- fork 代价高
站在操作系统的角度，创建一个进程的代价是很高的，需要分配很多内核资源，需要将内存映像从父进程复制到子进程。

- 父子进程通信复杂
父进程“fork”子进程时，文件描述符可以通过内存映像复制从父进程传到子进程，但“fork”完成后，父子进程通信就比较麻烦了，需要采用 IPC（Interprocess Communication）之类的进程通信方案。例如，子进程需要在 close 之前告诉父进程自己处理了多少个请求以支撑父进程进行全局的统计，那么子进程和父进程必须采用 IPC 方案来传递信息。

- 并发连接数量有限
如果每个连接存活时间比较长，而且新的连接又源源不断的进来，则进程数量会越来越多，操作系统进程调度和切换的**频率也越来越高，系统的压力也会越来越大。因此，一般情况下，PPC 方案能处理的并发连接数量最大也就几百。

### prefork

Prefork 就是提前创建进程（pre-fork）系统在启动的时候就预先创建好进程，然后才开始接受用户的请求，当有新的连接进来的时候，就可以省去 fork 进程的操作，让用户访问更快、体验更好。prefork 的基本示意图是：
![](%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8FPPC%E4%B8%8ETPC/EA70BFC1-CD95-418B-B388-CE88AFC6439F.png)


## TPC
> Thread Per Connection，新连接就建线程处理, TPC 实际上是解决或者弱化了 PPC fork 代价高的问题和父子进程通信复杂的问题。  

![](%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8FPPC%E4%B8%8ETPC/8263F46C-71BF-4D59-962E-C11B3A322176.png)
父进程接受连接（图中 accept）。
父进程创建子线程（图中 pthread）。
子线程处理连接的读写请求（图中子线程 read、业务处理、write）。
子线程关闭连接（图中子线程中的 close）。


和 PPC 相比，主进程不用“close”连接了。原因是在于子线程是共享主进程的进程空间的，连接的文件描述符并没有被复制，因此只需要一次 close 即可。

无须进程间通信，但是线程间的互斥和共享又引入了复杂度，可能一不小心就导致了死锁问题。

多线程会出现互相影响的情况，某个线程出现异常时，可能导致整个进程退出（例如内存越界）。

除了引入了新的问题，TPC 还是存在 CPU 线程调度和切换代价的问题。因此，TPC 方案本质上和 PPC 方案基本类似，在并发几百连接的场景下，反而更多地是采用PPC 的方案，因为 PPC 方案不会有死锁的风险，也不会多进程互相影响，稳定性更高。

### prethread
和 prefork 类似，prethread 模式会预先创建线程，然后才开始接受用户的请求，当有新的连接进来的时候，就可以省去创建线程的操作

![](%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8FPPC%E4%B8%8ETPC/FBE19EEA-B583-403D-9DCC-386696B2A66D.png)
Prethread 理论上可以比 prefork 支持更多的并发连接，Apache 服务器 MPM worker 模式默认支持 16 × 25 = 400个并发处理线程。
